## Running DFSIO Benchmark with Reduced Parameters

The DFSIO benchmark is a performance testing tool provided with Hadoop, which allows you to analyze the I/O performance of an HDFS cluster. This guide will walk you through adjusting the parameters of the DFSIO benchmark to accommodate limited disk space.

### Adjusting Benchmark Parameters

Given the constraint of having only 55 GB of available disk space, we need to reduce the parameters of the DFSIO benchmark to stay within this limit. The key parameters we can adjust are the number of files (`nrFiles`) and the file size (`fileSize`).

#### Write Performance Benchmark

To reduce the disk space required for the write performance benchmark, we'll adjust the number of files and the file size. We'll set `nrFiles` to 18 and `fileSize` to 500 MB.


```sh
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-*-tests.jar TestDFSIO -write -nrFiles 18 -fileSize 500
```

#### Read Performance Benchmark

Similarly, for the read performance benchmark, we'll use the same adjusted parameters as the write benchmark: `nrFiles` set to 18 and `fileSize` set to 500 MB.


```sh
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-*-tests.jar TestDFSIO -read -nrFiles 18 -fileSize 500
```

#### Cleanup

After running the benchmarks, it's a good practice to clean up the files generated by the benchmarking process. We'll use the following command to clean up:


```sh
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-*-tests.jar TestDFSIO -clean
```

### Conclusion

By adjusting the parameters of the DFSIO benchmark, we've ensured that we stay within the available disk space while still being able to analyze the I/O performance of the HDFS cluster.

